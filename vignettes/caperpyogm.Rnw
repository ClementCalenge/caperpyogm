\documentclass[a4paper]{article}
%\VignetteEngine{knitr::knitr}
%\VignetteIndexEntry{Estimation of the Number of Male Capercaillie on Leks of the French Pyrenees Mountains from 2010 to 2019}
%\VignetteDepends{knitr,ggplot2,dplyr,rjags,MCMCvis,rlang, purrr,tidyr,bayesplot, ade4, ggridges, gridExtra, coda}
\usepackage{fancyvrb}
\usepackage{color}
\usepackage{url}
\usepackage{amsfonts}
%\usepackage{pdfcolmk}
\usepackage{epsfig}
\usepackage[colorlinks=true,linkcolor=blue,urlcolor=blue,citecolor=blue]{hyperref}
\usepackage{longtable}
%\usepackage{natbib}
\usepackage{ucs}
\usepackage{savesym}
\savesymbol{iint}
\savesymbol{iiint}
\usepackage{amsmath}
\usepackage{rotating}
\usepackage{appendix}
%\usepackage[utf8]{inputenc}
\newlength{\defaultparindent}
\setlength{\defaultparindent}{\parindent}
\newenvironment{Default Paragraph Font}{}{}
\newcommand{\INT}[1]{\stackrel{\circ}{#1}}
\topmargin -1.5cm
\headheight 0.5cm
\headsep 1.0cm
\topskip 0.5cm
\textheight 24.5cm
\footskip 1.0cm
\oddsidemargin 0.0cm
\evensidemargin 0.0cm
\textwidth 16cm
\parskip 0.2cm
\parindent 1.0cm
\baselineskip 0.2cm



\title{Supporting information of the article: The participatory
  monitoring of the capercaillie in the
  French Pyrenees}
\author{Cl\'{e}ment Calenge et al.,\\
  Office Fran\c{c}ais de la Biodiversit\'{e}\\
  Saint Benoist -- 78610 Auffargis -- France.} 
\date{}
\setlength{\parindent}{0cm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\maketitle
\tableofcontents

<<setup, include=FALSE, cache=FALSE>>=
# set global chunk options
library('knitr')
opts_chunk$set(fig.path="caperpy-",
               fig.align="center",
               fig.show="hold",
               echo=TRUE,
               results="markup",
               fig.width=10,
               fig.height=10, out.width='\\linewidth',
               out.height='\\linewidth',
               cache=FALSE,
               dev='png',
               concordance=TRUE,
               error=FALSE)
opts_knit$set(aliases = c(h = 'fig.height',
              w = 'fig.width',
              wo='out.width',
              ho='out.height'))
options(replace.assign=TRUE,width=60)
set.seed(9567)
@


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%                                                            %%%%
%%%%                  The vignette starts here                  %%%%
%%%%                                                            %%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newpage

\section*{Introduction}


This vignette is the supplementary material of the article of Calenge
et al. (in prep.). The aim of this paper is to estimate the numbers of
capercaillie cocks in the 5 geographic regions of the French Pyrenees
mountains, for each two-year period between 2010 and 2019. A companion
package named \texttt{caperpyogm} contains the data and functions used
for this paper, and is required to reproduce the calculations in this
document. The present document is also available as a vignette of this
package. To install this package, first install the package
\texttt{devtools} and use the function \texttt{install\_github} to
install \texttt{caperpyogm}:

<<eval=FALSE>>=
## If devtools is not yet installed, type
install.packages("devtools")

## Install the package caperpyogm
devtools::install_github("ClementCalenge/caperpyogm", ref="main")
@ 

\textit{Remark}: on Windows, it is required to also install the Rtools
(\url{https://cran.r-project.org/bin/windows/Rtools/}) on your
computer to have a working \texttt{devtools} package (see
\url{https://www.r-project.org/nosvn/pandoc/devtools.html}).\\

Throughout this vignette, we suppose that the reader is familiar with
the model developed in this paper. Nevertheless, we present a brief
reminder on this model in this vignette. This model combines
three datasets:\\

\begin{enumerate}
\item the results of counts of singing capercaillie cocks carried out
  every two-year period on leks, which allow to model the time changes
  in the mean cock number on the different types of leks (KAL = known
  active leks; KIL = known leks with indeterminate activity status; UL
  = leks unknown at the time of the definition of the
  sampling design), and in the different geographic regions;\\

\item the results of the search for new ULs in grid cells randomly
  selected in the study area. This dataset was required to estimate
  the number of ULs on our study area.\\

\item the results of an experiment carried out to estimate the lek
  detection probability. This experiment involved both experienced or
  inexperienced observers searching for leks unknown to
  them (but known to us) in selected grid cells.\\
\end{enumerate}

We developed two sub-models for (i) the mean number of males actually
present on a lek of a given type (KAL, KIL, UL), during a given period
and within a given geographic region, and (ii) the number of ULs in
each geographic region.\\

In this document, we describe this study in detail:\\

\begin{itemize}
\item In section \ref{sec:notations-1}, we present in a table all
  mathematical notations used in the article and in the present
  vignette.\\

\item In section \ref{sec:notat-model-descr}, we give a brief reminder
  on the structure of the model used to estimate the number of
  capercaillie cocks at different spatial scales, and we show how to
  use the datasets and functions of the package to reproduce the
  calculations of the article. Note that all the functions of the
  package have a very detailed help page explaining how they should be
  used. This section contains additional analyses not presented in the
  paper (residual analysis, analysis of the convergence and the mixing
  of MCMC chains, sensitivity to outliers, etc.).\\

\item In section \ref{sec:other-models-detect}, we demonstrate how a
  cross-validation approach was used to select the best detection
  model for the lek censuses.\\

\item In section \ref{sec:lek--281}, we study more in detail the
  influence of the lek \# 281 on the population size estimation,
  because lek is characterized by a strong residual in our model. \\

\item In section \ref{sec:sens-our-model}, we considered in detail the
  criticisms of the N-mixture models by \cite{Barker2017} and
  \cite{Link2018}. In particular, we used simulations to assess the
  effect of both unaccounted heterogeneity in detection probability
  and accidental double counting on the estimated number of males.\\
  
\item In section \ref{sec:history-program}, we give additional
  elements describing the history of the monitoring program. In
  particular, we describe how the discovery that the number of cocks
  on ULs was larger than expected a priori affected our monitoring
  program.\\ 
\end{itemize}



\section{Notations}
\label{sec:notations-1}

We present, in the table below, the notations used in this paper. We
distinguish several types of notations:\\

\begin{itemize}
\item D: data used to fit the model
\item P: stochastic parameter estimated with MCMC
\item N: other notations\\
\end{itemize}

In the table below, we give:\\

\begin{itemize}
\item the notation
\item the type of notation
\item a description of the variable or parameter\\
\end{itemize}


<<results="asis", echo=FALSE>>=

dataf <- data.frame(
    Notation=c("$y_{i,t,k}$",
               "$b(t)$",
               "$N_{i,b(t)}$",
               "$p_{i,t,k}$",
               "$\\alpha_d$",
               "$\\beta_d$",
               "$o_{i,t,k}$",
               "$e_{g(i),t}$",
               "$\\sigma_e$",
               "$\\lambda_{i,b(t)}$",
               "$\\kappa_{g(i),\\ell(i),b(t)}$",
               "$\\nu_{u(i)}$",
               "$\\eta_i$",
               "$\\epsilon_{i,b(t)}$",
               "$\\mu_{g(i),\\ell(i)}$",
               "$\\sigma_{\\kappa}$",
               "$\\sigma_{\\nu}$",
               "$\\sigma_{\\eta}$",
               "$\\sigma_{\\epsilon}$",
               "$z_q$",
               "$f_q$",
               "$s_q$",
               "$b_q$",
               "$r_q$",
               "$h_q$",
               "$\\pi_q$",
               "$a_{g(q)}$",
               "$b_{g(q)}$",
               "$d$",               
               "$\\beta$",
               "$\\alpha$",
               "$S_c$",
               "$D_c$",
               "$N_c$",
               "$\\delta$",
               "$e(c)$",
               "$\\zeta_{e(c)}$",
               "$S_{g\\ell}$",
               "$Q$",
               "$n_{g\\ell b}$",
               "$n_b$"),
    Type=c("D",
           "N",
           "P",
           "P",
           "P",
           "P",
           "D",
           "P",
           "P",
           "P",
           "P",
           "P",
           "P",
           "P",
           "P",
           "P",
           "P",
           "P",
           "P",
           "D",
           "D",
           "D",
           "P",
           "D",
           "D",
           "P",
           "P",
           "P",
           "P",
           "P",
           "P",
           "D",
           "D",
           "D",
           "P",
           "N",
           "P",
           "D/P",
           "D",
           "P",
           "P"),
    Description=c("Number of detected males during census $k$ of year $t$ on lek $i$",
                  "Index of the two-year period containing year $t$",
                  "Number of males actually present on lek $i$ during the two year-period $b(t)$",
                  "Probability of detection of a male present on lek $i$ during census $k$ of year $t$",
                  "Intercept of the cock detection model",
                  "Slope of the number of observers in the cock detection model",
                  "Number of observers participating to census $k$ of year $t$ on lek $i$",
                  "Random effect of year $t$ on cock detectability in geographic region $g$",
                  "Standard deviation of random effects of the years on the cock detectability",
                  "Expectation of the Poisson distribution used for the number of males on lek $i$ during period $b(t)$",
                  "Parameter describing the average number of males during period $b(t)$ on a lek of type $\\ell(i)$ in region $g(i)$",
                  "Random effect of natural unit $u(i)$",
                  "Random effect of lek $i$",
                  "Overdispersion residual",
                  "Mean of the average cock numbers during period $b(t)$ on leks of type $\\ell(i)$ in region $g(i)$",
                  "Standard deviation of the average cock numbers during period $b(t)$ on leks of type $\\ell(i)$ in region $g(i)$",
                  "Standard deviation of the random effects of natural units",
                  "Standard deviation of the random effects of leks",
                  "Standard deviation of the overdispersion residuals",
                  "Whether the cell $q$ contains an unknown lek detected during a search carried out within the framework of our program",
                  "Whether the cell $q$ was sampled in 2018--2019",
                  "Whether the cell $q$ contains an unknown lek detected before the sampling of the cell within the framework of our program",
                  "Whether the cell $q$ actually contains an unknown lek",
                  "Proportion of the cell $q$ covered by the capercaillie potential presence area",
                  "Whether the cell $q$ already contains a known lek",
                  "Probability that the cell $q$ contains an unknown lek",
                  "Intercept of the model predicting $\\pi_q$",
                  "Slope of $r_q$ in the model predicting $\\pi_q$",
                  "Slope of $h_q$ in the model predicting $\\pi_q$",
                  "Probability of detection of an unknown lek during the search of a grid cell",
                  "Probability that an unknown lek present in the cell was discovered prior to its sampling",
                  "Number of known leks present in grid cell $c$ included in the search sector",
                  "Number of known leks present in grid cell $c$ detected by the observer",
                  "Number of known leks present in grid cell $c$",
                  "Detection probability of a lek during a search, given that the lek is in the search sector",
                  "Level of experience of the observers searching the cell $c$",
                  "Probability that the search sector defined by the observer with experience $e(c)$ includes a lek present in a cell",
                  "Number of leks of type $\\ell$ in region $g$ (to be estimated for ULs)",
                  "Number of grid cells in the sampling frame",
                  "Number of males on leks of type $\\ell$ during period $b$ in region $g$",
                  "Number of males on all leks of the mountain range during period $b$"
                  ))
library(xtable)

xt <- xtable(dataf, align="lllp{12cm}")
print(xt, include.rownames=FALSE,
      sanitize.text.function = function(x) {x}, floating=FALSE)
@ 




\section{Model description and model fit}
\label{sec:notat-model-descr}

We describe in this section the two sub-models required for the
estimation of the numbers of capercaillie cocks in the five
geographical regions of the Pyrenees, for each two-years period
between 2010 and 2019.

\subsection{Count model}
\label{sec:model-description}

\subsubsection{ Model description}
\label{sec:model-description-1}

We first describe the sub-model of the mean number of males detected
during the lek censuses carried out in the French Pyrenees mountains
between 2010 and 2019.\\

Let $y_{i,t,k}$ be the number of males counted during census $k$ of
year $t$ on lek $i$. We model these counts with a N-mixture model. We
assume that the number of detected animals can be described using a
binomial distribution:
\begin{equation}
  \label{eq:eqy}
y_{i,t,k} \sim \mathcal{B}(N_{i,b(t)}, p_{i,t,k})
\end{equation}
where $N_{i,b(t)}$ is the actual number of males actually present on
lek $i$ during the two-years period $b(t)$ including year $t$, and
$p_{i,t,k}$ is the corresponding detection probability. We suppose the
following detection model: 
\begin{equation}
  \label{eq:detect}
\mbox{logit } p_{i,t,k} = \alpha_d + \beta_d \times o_{i,t,k} + e_{g(i),t}
\end{equation}
where $o_{i,t,k}$ is the number of observers present on lek $i$ during
census $k$ of year $t$, $\alpha_d$ is the intercept of the
model, $\beta_d$ is the slope, and $e_{g(i),t}$ is a Gaussian random
effect characterizing year $t$ in the geographic region $g(i)$ where
the lek $i$ is located:
$$
e_{g(i),t} \sim \mathcal{N}(0, \sigma_e)
$$
We discuss alternative detection models in section
\ref{sec:other-models-detect}.\\

Moreover, we assume that the actual number of males $N_{i,b(t)}$ on
lek $i$ during the two-year period $b(t)$ that includes year $t$
can be described using a Poisson distribution:
\begin{equation}
  \label{eq:eqN}
  N_{i,b(t)}\sim \mathcal{P}(\lambda_{i,b(t)})
\end{equation}
And we suppose the following log-linear model for the expectation of
this distribution:
\begin{equation}
  \label{eq:eqlambda}
\log \lambda_{i,b(t)} = \kappa_{g(i),\ell(i),b(t)} + \nu_{u(i)}\times
I(\ell(i) =2) + \eta_i + \epsilon_{i,b(t)}
\end{equation}
Where $\kappa_{g(i),\ell(i),b(t)}$ is a random intercept
characterizing type $\ell(i)$ of lek $i$ (1 for KALs, 2 for KILs,
and 3 for ULs) in the geographic region $g(i)$ that contains lek $i$,
during two-years period $b(t)$ that includes year $t$; $\nu_{u(i)}$ is a
random effect characterizing natural unit $u(i)$ that contains the
lek $i$ (note that a random effect characterizing the natural unit is
only included for KILs, see the article for an explanation); $\eta_i$ is a
random effect characterizing lek $i$, and
$\epsilon_{i,b(t)}$ is a Gaussian overdispersion residual.\\

We furthermore assume that the following distributions describe the parameters:
\begin{eqnarray*}
\kappa_{g(i),\ell(i),b(t)} & \sim & \mathcal{N}(\mu_{g(i),\ell(i)},
  \sigma_{\kappa})\\
\nu_{u(i)} & \sim & \mathcal{N}(0,\sigma_\nu) \\ 
\eta_{i} & \sim & \mathcal{N}(0,\sigma_\eta^{\ell(i)})\\
\epsilon_{i,b(t)} & \sim & \mathcal{N}(0,\sigma_\epsilon)  
\end{eqnarray*}

\textit{Remark}: We defined five geographic regions for the KALs (1 =
western foothills, 2 = central foothills, 3 = central high range, 4 =
eastern high range, 5 = western high range), but since we had less
data for the other types of leks, we defined only three geographic
regions for the KILs (foothills, western high range, central and
eastern high range) and only one for ULs.


\subsubsection{Fit of the count model}
\label{sec:fitmc}

We load the library \texttt{caperpyogm}, which contains the data and
the functions that we used to fit the model:


<<load-library>>=
library(caperpyogm)
@ 

All the datasets of the package are ``lazy-loaded'', i.e. they are
immediately available to the user:

<<description-lekcounts>>=
head(lekcounts)
@ 

This data.frame contains the results of the censuses carried out on all
leks in the Pyrenees mountains from 2010 to 2019. For each census,
this data.frame contains:\\ 

\begin{itemize}
\item The lek label, numbered from 1 to 330
\item The two-year period during which  the census occurred
\item The number of observers. We have subtracted 2 to the number of
  observers, to improve the mixing of the MCMC chains.
\item The number of males counted on the lek
\item The ID of geographic region containing the lek. Note that in
  this dataset, the geographic regions are not yet recoded (i.e. there
  are still 5 regions for KILs and ULs; these regions will be recoded
  into three and one region respectively by the function
  \texttt{dataCount2jags} below).
\item The type of the lek (1 = KAL, 2 = KIL, 3 = UL)
\item The label of the natural unit containing the lek
\item The year during which the census occurred.\\
\end{itemize}

We have programmed the model in JAGS:

<<JAGS-model-paper>>=
cat(modelCountDetectBinREY)
@ 


We now use the function \texttt{dataCount2jags} to prepare the data to
fit the JAGS model. Note that this functions recodes the 5 regions
into three regions for the KILs (region 1 = foothills ; region 2 =
eastern and central high range; region 5 = western high range) and one
region for the ULs (region 1) :


<<preparation-model-count>>=
dataList <- dataCount2jags(lekcounts$lek, lekcounts$period,
                           lekcounts$nbobs, lekcounts$nbmales,
                           lekcounts$gr, as.numeric(factor(lekcounts$type)),
                           lekcounts$natun, lekcounts$year)
@ 


We can now use the function \texttt{fitModelCount} to fit this
model. WARNING: THIS CALCULATION TAKES A VERY LONG TIME (several hours)
!!!! Note that we have included the results of this calculation as a
dataset of the package, so that the reader does not need to launch
this function to reproduce further calculations:

<<fit-model-count, eval=FALSE>>=
coefModelCountDetectBinREY <- fitModelCount(dataList, "modelCountDetectBinREY")
@ 



\subsubsection{MCMC chains mixing}
\label{sec:conv-model-fit}

Once the MCMC samples have been obtained, we can plot the chain for a
visual examination of the mixing. We present the traceplot for the
parameters $\kappa$ below:

<<traceplot-kappa>>=
library(bayesplot)
library(MCMCvis)
cm <- MCMCchains(coefModelCountDetectBinREY,
                 params=c("kappa","sigmakappa","sigmaepsilon","sigmaeta",
                          "sigmanu", "interceptpd","pente1pd","sigmaREY"),
                 mcmc.list=TRUE)
for (i in 1:length(cm)) {
    for (j in c("sigmakappa","sigmaepsilon","sigmaeta[1]",
                "sigmaeta[2]","sigmaeta[3]","sigmanu","sigmaREY"))
        cm[[i]][,j] <- 1/cm[[i]][,j]
}
mcmc_trace(cm, regex_pars="kappa")
@ 

We also present the traceplot for the variances of the state model:

<<traceplot-sigma>>=
mcmc_trace(cm, regex_pars=c("sigmakappa","sigmaepsilon","sigmaeta",
                            "sigmanu"))
@ 

Finally, we present the parameters for the detection model:

<<traceplot-detection>>=
mcmc_trace(coefModelCountDetectBinREY,
           regex_pars=c("REY","interceptpd","pente1pd","sigmaREY"))
@ 

We also calculate the statistic of Gelman and Rubin (1992) for the
parameters. To save some space, we do not show the results of this
diagnostic in this vignette and leave it to the reader to check the
correct mixing based on this diagnostic:

<<gelman-diagnostic, eval=FALSE>>=
gelman.diag(cm)
@ 


\subsubsection{Goodness of fit}
\label{sec:goodness-fit}


We then check the goodness of fit of the model. We simulate $M$
virtual datasets (one per MCMC sample) and consider several summary
statistics (see below). For each one, we compare the observed
statistics (calculated on the actual dataset) with the statistical
distributions of the simulated values. We first use the function
\texttt{simulateModelCount} to simulate the datasets. WARNING!!! THIS
CALCULATION CAN BE VERY LONG (about half an hour). Note that we have
included the results of this calculation as a dataset of the package,
so that the reader does not need to launch this function to reproduce
further calculations:

<<simulate-datasets, eval=FALSE>>=
simBinREY <- simulateModelCount(coefModelCountDetectBinREY, dataList)
@ 

We can then examinate the distribution of the residuals of the model: 

<<residuals-prediction>>=
plot(predict(simBinREY), residuals(simBinREY),
     xlab="Predicted number of males",
     ylab="Standardized residuals")
@ 

Here, each point corresponds to a census.  These residuals do not
present any problematic pattern, except a very small number of
standardized residuals greater than 6. Note that the group of censuses
with a residual greater than 6 correspond to the same lek. Indeed,
this appears clearly if we calculate the residuals at the lek level:

<<residuals-prediction-lek>>=
plot(predict(simBinREY, groupingFactor="lek"),
     residuals(simBinREY, groupingFactor="lek"),
     xlab="predictions",
     ylab="residuals")
@

Here, each point corresponds to one lek. The largest residual
correspond to the lek 281, a UL that was discovered in 2013 and
censused only this year. We study more in details in section
\ref{sec:lek--281} the influence of this lek on the estimation.\\



\subsubsection{Test of goodness of fit}
\label{sec:test-goodness-fit}

We calculate various statistics to test the goodness of fit of our
model; the first statistics is the mean number of males
$\hat{y}_{itk}$ for each census, averaged across all our simulated
datasets. We can then calculate the chi-square statistics for the
observed dataset:
$$
\chi^2 = \sum_{i,t,k} \frac{(y_{itk}-\hat{y}_{itk})^2}{\hat{y}_{itk}}
$$
We can then compare the observed $\chi^2$ to the distribution of
this statistics under the simulated datasets. We calculate below the
proportion of simulated $\chi^2$ lower than the observed value:

<<calc-chi2>>=
od <- simBinREY$origData
sim <- simBinREY$sim
ry <- od$nbmales

## Chi2 obs
chi2obs <- (sum(((ry-apply(sim,1,mean))^2)/apply(sim,1,mean)))

## distribution of simulated Chi2
chisq <- ((sim-apply(sim,1,mean))^2)/apply(sim,1,mean)
ch <- (colSums(chisq))

## proportion of simulated chi-square values > observation
mean(ch>=chi2obs)
@

The observed chi-square is at the center of the simulated statistical
distribution.\\

We also compared the observed total number of detected males over the
10 years of the study with the distribution of simulated values:

<<crit-nb-tot>>=
mean(colSums(sim)>=sum(ry))
@ 

...which is also at the center of the simulated statistical
distribution.  We calculated a 80\% credible interval on the expected
detected number of males (using the simulated datasets), and computed
the proportion of censuses falling in the 80\% credible interval:

<<crit-per-lek-count>>=
q1 <- apply(sim,1,quantile,0.1)
q2 <- apply(sim,1,quantile,0.9)
mean((ry>=q1)&(ry<=q2))
@ 

...also indicating a good fit.\\

We define below a function named \texttt{comparef}, which calculates
the proportion of simulated numbers greater than or equal to the
observed number, for each level of a variable of the observed dataset
\texttt{od}:

<<comparef>>=
comparef <- function(na)
{
    ta <- tapply(ry,na,sum)
    app <- apply(sim,2,function(x) tapply(x,na,sum))
    sapply(1:nrow(app), function(i) mean(ta[i]>app[i,]))
}
@ 

We used this function to compare observed values with the statistical
distribution of simulated values for different levels of an
explanatory variable. For example, we assessed the fit within each
geographic region (and use as statistic for each one the total number
of animals detected in a region over the 10 years of the study):

<<comparef-gr>>=
comparef(od$gr)
@ 

We can also assessed the fit for each level of different combinations
of explanatory variables. For example we assessed the goodness of fit
for each combination of geographic region, type of lek, and period:

<<comparef-combination>>=
comparef(paste0(od$gr,"-",od$type,"-",od$period))
@ 

We have checked the goodness of fit of our model on other variables
and combination of variables (leks, gr-years, etc.). We leave it to
the reader to play with this function to check other variables if they
want.


\subsubsection{Identifiability of the parameters}
\label{sec:identifiability}

We checked the identifiability of the parameters of interest in our
model using the coefficient $\tau$ described by \cite{Garrett2000},
which measures the overlap between the prior and the posterior
distribution of a parameter. Let $x$ be a parameter of the model,
$P(x)$ is the prior distribution for this parameter, and
$P(x|\mathbf{D})$ is its posterior distribution. Then, the parameter
$\tau$ measures the overlap:
$$
\tau = \int_x \mbox{min}( P(x), P(x|\mathbf{D}) ) dx
$$
This parameter is close to 1 when the dataset \textbf{D} does not
bring a lot of information on the parameter $x$.\\

We used the functions \texttt{overlapPriorPost} from the package
\texttt{caperpyogm} (see the help page of this functiond) to calculate
the coefficient $\tau$ for the variances of random effects in the
model, and the function \texttt{plotOverlap} from the same package to
visualize how the posterior distribution differs from the prior
distribution of these parameters:

<<fig.width=10, fig.height=5, out.width='\\linewidth',out.height='0.5\\linewidth'>>=
## Use the MCMC samples from the model coefModelCountDetectBinREY 
rs <- do.call(rbind, coefModelCountDetectBinREY)

## Detects the name of the parameters for which tau should be calculated
library(stringr)
nam <- c("sigmaREY", "sigmaepsilon","sigmaeta","sigmakappa",
         "sigmanu")
nam <- unlist(lapply(nam, function(z) colnames(rs)[str_detect(colnames(rs),z)]))


## For each parameter, calculates the value of tau:
lb <- sapply(nam, function(na) {
    tau <- overlapPriorPost(coefModelCountDetectBinREY, na,
                            prior="dgamma(den$x[j],0.01, 0.01)", from=0, to=1000, n=10000)
    return(tau)
})

## Builds the data.frame required by plotOverlap
df <- data.frame(Parameter=nam, tau=lb)

## Mathematical symbols used for each parameter (see ?plotmath)
namo <- paste0("expression(",  c("sigma[e]", "sigma[epsilon]",
                                 "sigma[eta]^(1)", "sigma[eta]^(2)",
                                 "sigma[eta]^(3)",
                                 "sigma[kappa]","sigma[nu]"),")")
df$namo <- namo

## Prior used for these variances
df$prior <- "dgamma(z,0.01,0.01)"

## customize xy limits for the plots, for a better viz
## of the posterior distribution of each parameter
df$from <- 0.01
df$to <- 10
df$to[1] <- 100
df$to[2] <- 600
df$to[6] <- 600


plotOverlap(coefModelCountDetectBinREY, df, cex=1)

@

This table shows the value of the $\tau$ parameters and quick plots of
the prior (dashed lines) and posterior (solid lines) distribution for
each parameter. All the variance parameters are correctly identified,
with very low values of $\tau$. We build the same plot for the effects
of regions/type of leks/two years period $\kappa_{glb}$:

<<fig.width=5, fig.height=10, out.width='0.5\\linewidth',out.height='\\linewidth'>>=

## Detects the name of the parameters for which tau should be calculated:
## startinq with kappa
nam <- colnames(rs)[str_detect(colnames(rs),"^kappa")]

## note that some of the parameters are not of interest:
## there is only one region for ULs and three regions for KILs.
## (to facilitate calculations, we defined a three way table
##  in JAGS crossing 5 regions, 3 types of leks and 5 periods, but
##  some of these parameters are not used in the model). 
## For KILS, only regions 1,2,5 are valid
## For ULs, only region 1.
## For KALs, all regions are valid
## We remove unused parameters:
nam <- nam[!(str_detect(nam, "3\\,2\\,.")|
             str_detect(nam, "4\\,2\\,.")|
             str_detect(nam, "[2-5]\\,3\\,."))]

## For each parameter, calculates the value of tau:
lb <- sapply(nam, function(na) {
    tau <- overlapPriorPost(coefModelCountDetectBinREY, na,
                            prior="dnorm(den$x[j],0, sqrt(10))", from=-10, to=10)
    return(tau)
})

## Builds the data.frame required by plotOverlap
df <- data.frame(Parameter=nam, tau=lb)

## Mathematical symbols used for each parameter (see ?plotmath)
namo <- paste0("expression(", gsub(",", "", nam[3:11]),")")
df$namo <- namo

## Prior used for these variances
df$prior <- "dnorm(z,0,sqrt(10))"

## The xy limits for the plots
df$from <- -4
df$to <- 4


plotOverlap(coefModelCountDetectBinREY, df, cex=1)
@ 

Similarly, all distributions seem to be correctly identified. Finally,
we also present the intercept and slope of the number of observers for
the detection model:


<<fig.width=10, fig.height=2.5, out.width='\\linewidth',out.height='0.25\\linewidth'>>=
## Detects the name of the parameters for which tau should be calculated:
## startinq with kappa
nam <- c("interceptpd","pente1pd")

## For each parameter, calculates the value of tau:
lb <- sapply(nam, function(na) {
    tau <- overlapPriorPost(coefModelCountDetectBinREY, na,
                            prior="dnorm(den$x[j],0, sqrt(10))", from=-10, to=10)
    return(tau)
})

## Builds the data.frame required by plotOverlap
df <- data.frame(Parameter=nam, tau=lb)

## Mathematical symbols used for each parameter (see ?plotmath)
namo <- paste0("expression(", c("alpha[d]","beta[d]"),")")
df$namo <- namo

## Prior used for these variances
df$prior <- "dnorm(z,0,sqrt(10))"

## The xy limits for the plots
df$from <- -4
df$to <- 4


plotOverlap(coefModelCountDetectBinREY, df, cex=1)
@ 


These two parameters are also correctly identified.



\subsection{Grid cells search model}
\label{sec:grid-model}

\subsubsection{Model description}
\label{sec:model-description-2}

Consider a grid cell $q$ sampled by our protocol.  If this cell was
sampled before 2018, our protocol implied that observers should search
UL in the sampled cell in every case. An update of our grid cells
sampling frame in 2018--2019 resulted in the inclusion of additional
information in the sampling frame; indeed, several ULs have been
discovered between 2010 and 2017 by the network of observers outside
the framework of our monitoring (e.g. resulting either from accidental
discovery, from compilation of local knowledge, or from local
initiatives leading to the search for new leks). See a more detailed
explanation of this update of our sampling frame in section
\ref{sec:history-program}. Therefore, some of the grid cells sampled
in 2018-2019 may already contain a UL discovered previously by the
network. In such cases, no search was organized in the sampled
grid cell, since the occurrence of a UL was already known.\\

Let $z_q$ be a binary variable taking a value of 1 if this cell
contains a UL detected during a search organized within the framework
of our program and a value of 0 otherwise (thus, if a cell $q$
contains a UL discovered prior to its sampling, $z_q=0$). Let $f_q$ be
a binary variable taking a value of 1 if the cell was randomly sampled
in 2018 or 2019, and a value of 0 otherwise. Finally, let $s_q$ be a
binary variable taking a value of 1 if cell $q$ included a UL
discovered prior to its sampling and a value of 0 otherwise.\\

We defined the following model to describe the probability
$\pi_q$ of UL presence in a grid cell $q$:

\begin{eqnarray*}
  z_q & \sim & \mathcal{B}(b_q \times (1-s_q)\times \beta)\\
  s_q & \sim & \mathcal{B}(b_q \times f_q \times \alpha)\\
  b_q & \sim & \mathcal{B}(\pi_q)\\
\end{eqnarray*}

where $\beta$ is the detection probability during a grid cell search,
and $\alpha$ is the probability that a UL present in the cell was
discovered prior to its sampling. The parameters $\alpha,\beta,\pi_q$
are unknown and must be estimated.\\

We modeled the probability of presence of a UL in a grid
cell with:

\begin{equation}
  \label{eq:eqp}
  \mbox{logit } \pi_q = a_{g(q)} + b_{g(q)} \times r_q + d\times h_q
\end{equation}

where $r_q$ measures the proportion of the grid cell $q$ covered by
area of potential capercaillie presence (defined by experts in 2009,
before the onset of the program), and $h_q$ is a binary variable
taking a value of 1 if the grid cell $q$ contains a known lek and a
value of 0 otherwise. The intercept $a_{g(q)}$ and slope of the area
of potential presence $b_{g(q)}$ is
supposed to vary between geographical regions.\\

We estimated the parameter $\beta$ with the data collected during the
lek detection experiment. A sample of grid cells containing a known
number of known leks (but unknown to the observers) was drawn and each
cell was assigned to one observer. Two observers participated to this
experiment: one experienced observer and one inexperienced one. Let
$N_c$ be the number of known leks included in the grid cell $c$. The
observer searching this cell defines a search sector. Let $S_c$ be the
number of these known leks included in the search sector. Finally, let
$D_c$ be the number of known leks detected by the observer in this
sector. We define the binary variable $e(c)$ taking a value of 1 if
the observer searching the cell $c$ is experienced and a value of 0 if
the observer is inexperienced. We used the following model:
\begin{eqnarray*}
  D_c & \sim & \mathcal{B}(S_c, \delta)\\
  S_c & \sim & \mathcal{B}(N_c, \zeta_{e(c)})
\end{eqnarray*}
where $\delta$ is the probability to detec a lek during the search,
given that a lek is present in the search sector, and $\zeta_{e(c)}$
is the probability that the search sector defined by the observer
includes a lek. Note that this latter probability depends on the
experience of the observer. We supposed that the detection probability
$\beta$ was uniformly distributed between the minimum detection probability
$\delta\times\zeta_0$ (characterizing inexperienced observers) and
$\delta\times\zeta_1$ (characterizing highly experienced observers):
$$
\beta \sim \mathcal{U}( \delta\times\zeta_0 , \delta\times\zeta_1)
$$

Thus, the unknown parameters of our model are
$\{a_{g(q)}\}_{g=1}^3, \{b_{g(q)}\}_{g=1}^3, d, \delta, \zeta_{0},
\zeta_1$.

\subsubsection{Model fit}
\label{sec:model-fit}

We need two datasets to fit this model. First, the dataset
\texttt{gridSearch} contains the data collected during grid cells search:

<<description-gridSearch>>=
head(gridSearch)
@ 

For each grid cell search, this data.frame contains:\\

\begin{itemize}
\item The proportion of the grid cell covered by the area of potential
  capercaillie presence (as defined by a group of experts in
  2009, before the onset of the program).
\item Whether (1) or not (0) a UL was discovered during the cell
  search.
\item Whether (1) or not (0) the cell was sampled in 2018-2019
  (i.e. could possibly contain a UL discovered outside the
  framework of our program, prior to its sampling)
\item Whether (1) or not (0) the cell contained a UL
  discovered prior to its sampling.
\item The label of the geographic region containing the grid cell (1=
  Piemont, 2=High area, 3 = Pyrenees national parc).
\item Whether (1) or not (0) the grid cell contained a known lek.\\
\end{itemize}

We also need the data.frame \texttt{DetectionExpe}, containing the
data collected during the experiment designed to assess the
detectability of new leks during grid cells searches:

<<presentation-DetectionExpe>>=
DetectionExpe
@

For each grid cell sampled for this experiment, this data.frame
contains:\\

\begin{itemize}
\item Whether the observer was experienced or inexperienced.
\item The number of known leks in the cell.
\item The number of known leks present in the search sector defined by
  the observer.
\item The number of known leks detected by the observer.\\
\end{itemize}


We have programmed the model in JAGS:

<<JAGS-model-paper-ul>>=
cat(modelULPresence)
@ 

We prepare the datasets for the fit:

<<>>=
dataListQ <- datagrid2jags(gridSearch, DetectionExpe)
@ 

We can now use the function \texttt{fitModelGrid} to fit this
model. WARNING: THIS CALCULATION TAKES A VERY LONG TIME (several hours)
!!!! Note that we have included the results of this calculation as a
dataset of the package, so that the reader does not need to launch
this function to reproduce further calculations:

<<fit-model-grid, eval=FALSE>>=
coefModelULPresence <- fitModelGrid(dataListQ, "modelULPresence")
@ 

\subsubsection{MCMC chains mixing}
\label{sec:conv-model-fit-grid}

Once the MCMC samples have been obtained, we can plot the chains for a
visual examination of the chain mixing:

<<traceplot-gcs>>=
mcmc_trace(coefModelULPresence)
@ 

We also calculate the diagnostic of Gelman and Rubin (1992) for the parameters:

<<gelman-diagnostic-gcs, eval=FALSE>>=
gelman.diag(coefModelULPresence)
@ 

Mixing properties are excellent here.



\subsubsection{Goodness of fit}
\label{sec:goodness-fit-grid}


We then check the goodness of fit of the model. As for the count
model, we simulate $M$ virtual datasets (one per MCMC sample) and
consider several summary statistics (see below). For each one, we
compare the observed statistics (calculated on the actual dataset)
with the statistical distribution of simulated values. We first use
the function \texttt{simulateModelGrid} to simulate the
datasets. Fortunately, this function is faster than the one used for
the count model, so that it can readily be executed by the user:

<<simulate-datasets-grid>>=
sg <- simulateModelGrid(coefModelULPresence, dataListQ)
@ 

We can then calculate the proportion of simulated values lower
than the observed value of the total number of ULs discovered
in our study:

<<crit-tot>>=
obs <- sum(dataListQ$newUL)
sim <- colSums(sg$sim)
mean(sim<obs)
@

The observed value is at the center of the distribution expected under
our model. We can calculate the same proportion for each geographical
region (piemont or high mountains):

<<>>=
obs <- tapply(dataListQ$newUL, dataListQ$gr, sum)
sim <- apply(sg$sim,2,function(x) tapply(x, dataListQ$gr, sum))

## Region 1
mean(sim[1,]<obs[1])

## Region 2
mean(sim[2,]<obs[2])

@ 

The observed values are located within the distribution of simulated values.

\subsubsection{Identifiability of the parameters}
\label{sec:ident-param}

We also assessed the identifiability of the parameters of interest in
this model, using the parameter $\tau$ described by \cite{Garrett2000}
(see section \ref{sec:identifiability}):

<<>>=
rs <- do.call(rbind, coefModelULPresence)
nam <- c("P_inclusion_inex","P_inclusion_expe","P_detection",
         "pd$","pdprev$","a","b")
nam <- unlist(lapply(nam, function(z) colnames(rs)[str_detect(colnames(rs),z)]))


## For each parameter, calculates the value of tau:
lb <- sapply(nam, function(na) {
    if (str_detect(na, "^a")|str_detect(na,"^b")) {
        tau <- overlapPriorPost(coefModelULPresence, na)
    } else {
        tau <- overlapPriorPost(coefModelULPresence, na,
                                prior="dunif(den$x[j],0, 1)", from=0, to=1)
    }
    return(tau)
})

## Builds the data.frame required by plotOverlap
df <- data.frame(Parameter=nam, tau=lb)
namo <- paste0("expression(", c("zeta[0]","zeta[1]","delta","alpha", nam[5:8]),")")
df$namo <- namo
df$prior <- "dunif(z,0,1)"
df$prior[5:8] <- "dnorm(z,0,sqrt(10))"
df$from <- 0
df$to <- 1
df$from[5:8] <- -10
df$to[5:8] <- 10


plotOverlap(coefModelULPresence, df, cex=1)
@

The parameters of this model were not as precisely identified as for
the model of counts. The probability $\alpha$ is the less precisely
identified parameter; however this parameter is not a parameter of
interest: we included this parameter in our model to account for the
fact that we should not model the detection process during search
when it was known that a lek was present in a grid cell. Thus, the
weak identifiability for this parameter is not a problem. Other
parameters are more precisely identified, though there is still a
large imprecision for many of them -- in particular the parameters
estimated using our field experiment.  Future data collection will
allow to precise these posterior distributions, but meanwhile we will
accept these estimates.


\subsection{Estimation of the number of males in each region}
\label{sec:estim-numb-males}


Let $S_{g\ell}$ be the number of leks of type $\ell$ in region
$g$. Note that this number needs to be estimated for ULs (i.e. for
$\ell = 3$). The grid cell search model can be used to estimate
$S_{g3}$. We estimated this number with:

\begin{equation}
  \label{eq:ug}
\widehat{S_{g3}} = \sum_{q=1}^{Q} \pi_q
\end{equation}

where the probability $\pi_q$ is calculated for each grid cell $q$
with the equation \ref{eq:eqp}, and the sum is calculated over all the
grid cells of the sampling frame. Then, the number of males
$n_{g\ell b}$ in geographic region $g$ for lek type $\ell$
during period $b$ can be estimated with:
$$
\widehat{n_{g\ell b}} = \sum_{\ell=1}^3 S_{g\ell} \exp\left\{
  \kappa_{g,\ell,b} + I(\ell=2) \times \sigma^2_\nu/2 +
  \sigma^2_\eta/2 + \sigma^2_\epsilon/2 \right \}
$$

Of course, we can calculate one estimate $\widehat{n_{g\ell b}}$ per
MCMC iteration, so that the posterior distribution of the number of
males in a given region during a given period can be readily
obtained. Finally, the number of males over the whole mountain range
during a given period $b$ is calculated by:
$$
\widehat{n_{b}} = \sum_{g=1}^5 \sum_{\ell=1}^2 \widehat{n_{g\ell b}}
$$

We store the number of KAL and KIL in each one of the five regions in
R vectors:

<<>>=
NKAL <- c(14L, 64L, 76L, 48L, 46L)
NKIL <- c(6L, 80L, 102L, 32L, 96L)
@ 

We use the function \texttt{estimateNmales} to combine the two models
and estimate the number of males in the different geographical
regions. The frame of grid cells as an argument is required for the
estimation of the number of ULs in each region. This frame is
stored in the dataset \texttt{gridFrame}:

<<>>=
head(gridFrame)
@ 

This data.frame contains the following variables for each grid cell:\\

\begin{itemize}
\item proportion of the cell covered by the potential capercaillie
  presence area
\item whether the cell contains (1) or not (0) an already known lek
\item the geographic region (original partitioning in 5 regions)
\item the geographic region code used in the grid cell search model (1
  = piemont, 2 = high range)\\
\end{itemize}

<<>>=
nm <- estimateNmales(coefModelCountDetectBinREY, coefModelULPresence,
                     gridFrame, NKAL, NKIL)
@ 

The function \texttt{summary} shows the estimated number of males for
all two-year periods:  

<<>>=
summary(nm)
@ 

This function returns the point estimate of the population size each
two-year period (with a 80\% credible interval), the point estimate of
the rate of change of this size between the first and last period, and
the probability of the three scenarios: increasing population (actual
change rate $>$ 10\%), decreasing population (actual change rate $<$
-10\%), stability
(otherwise).\\

The function \texttt{distritime} shows the posterior distribution of
the estimated population size during the 5 periods:

<<>>=
distritime(getTotal(nm))
@ 

The function \texttt{showChangeRate} can be used to estimate the rate
of change of the population size between the first and last two-year
periods:

<<>>=
showChangeRate(nm)
@ 

Note that we can estimate the number of males in a given region with
the function \texttt{summary}. For example, for the region 1:

<<>>=
summary(nm,1)
@ 



\section{Assumptions on the detection process and on constant number
  of males within two-years periods}
\label{sec:other-models-detect}

\subsection{List of alternative models}
\label{sec:list-altern-models}

The population size estimation by a N-mixture model can be very
sensitive to the misspecification of the detection process
\cite{Link2018}. We considered several alternative models for this
process before choosing the approach detailed in our paper. We also
tried to check our assumption of a constant number of males within the
two-year periods. We describe these alternative models in this
section, and show in the next sections how we compared the different
models with cross-validation.\\

We recall the detection model used in the paper:
$$
\mbox{logit } p_{i,t,k} = \alpha_d + \beta_d \times o_{i,t,k} + e_{g(i),t}
$$
where $o_{i,t,k}$ is the number of observers partipating to $k$-th
census on lek $i$ during year $t$, and $e_{g(i),t}$ is a
Gaussian random effect describing the variation in detectability
during a given year in a given region. As already described, this
model is programmed for the JAGS software in the dataset
\texttt{modelCountDetectBinREY} of the package.\\

We first tested whether the year random effects were required in the
model, by fitting the simpler model:
$$
\mbox{logit } p_{i,t,k} = \alpha_d + \beta_d \times o_{i,t,k}
$$
i.e., the same model as before, but without the year random
effects. This model is programmed for the JAGS software in the dataset
\texttt{modelCountDetectBin}.\\

We also tested the model \texttt{modelCountDetectBin} by considering
one-year periods. Indeed, in our paper, we have supposed that the
number of males present in a given region did not vary within two-year
periods. Within a given period, the between-year variation in the
number of detected males was supposed to be caused by between-year
variability in the detection probability. We therefore tried to check
this assumption by setting $b(t)=t$ in equations \ref{eq:eqy},
\ref{eq:eqN}, and \ref{eq:eqlambda}, and by fitting the
binomial detection model without the random effects of the years.\\

We also tested whether an extra-binomial variation was required for
the detection process of our original model (i.e. with two-year
periods and year random effects), by modeling the number of detected
animals as a beta-binomial distribution (see \cite{Martin2011a}). That
is, we considered the following model:
\begin{eqnarray*}
\mbox{logit } d_{i,t,k} & = & \alpha_d + \beta_d \times o_{i,t,k} +
e_{g(i),t}\\
p_{i,t,k} & \sim & \mbox{Beta}\left( d_{i,t,k} \times
                   \frac{1-\delta^2}{\delta^2}, (1-d_{i,t,k}) \times
                   \frac{1-\delta^2}{\delta^2} \right )
\end{eqnarray*}
This model is programmed for the JAGS software in the dataset
\texttt{modelCountDetectBetaBinREY}.\\

Finally, we tested whether the relationship between the detection
probability and the number of observers was linear by including a
quadratic effect of this variable in our model:
$$
\mbox{logit } p_{i,t,k} = \alpha_d + \beta_d \times o_{i,t,k} +
\omega_d \times o_{i,t,k}^2
$$
This model is programmed for the JAGS software in the dataset
\texttt{modelCountDetectBinREYObs2}.\\

We compared these models using cross-validation. We describe in the
next subsections how we carried out this comparison.




\subsection{On the use of cross-validation to compare several
  models. Theory} 
\label{sec:use-cross-validation}


We have used the approach described by \cite{Vehtari2017} to compare
the different models for the detection process. This approach relies
on cross-validation and identifies, in a set of alternative models,
the model that return the best predictions of new data. We describe
the rationale behind this approach in this
section, and we show how we used it in the next section.\\

Consider two models $\mathcal{M}_0$ and $\mathcal{M}_1$ fitted to the
same dataset. These two models can be compared with the
\textit{expected log pointwise predictive density for a new dataset},
or \textbf{elpd}. First consider a simple observed dataset with $n$
statistical units, where each unit $i$ is characterized by a value of
a response variable $y_i$. For example, this dataset may contain the
numbers $y_i$ of detected cocks during each census $i$, among $n$
censuses carried out on a unique lek. We measure the quality of
prediction by a model of the data by calculating the elpd of the
model, i.e. by trying to predict the number of detected males in $n$
new censuses of the same lek at the same year, in the same
conditions.\\

\textbf{In theory}, for a given model -- say $\mathcal{M}_0$ -- this
criterion should be calculated by:
$$
\mbox{elpd} = \sum_{i=1}^n \int p_t(\tilde y_i) \log p(\tilde y_i|y, \mathcal{M}_0) d\tilde y_i
$$
where $\tilde y_i$ is the value of the variable $y$ for unit $i$ in
the new dataset (in our example, the number of detected males during
census $i$ on the lek in our new dataset).  The value of
$p_t(\tilde y_i)$ is the \textit{true} probability to obtain
$\tilde y_i$ (under the true process), and
$p(\tilde y_i|y, \mathcal{M}_0)$ the probability to obtain
$\tilde y_i$ under the model $\mathcal{M}_0$ fitted to the observed
dataset $y$. When the elpd criterion is high, the model closely
describes the reality.\\

\textbf{In practice}, we cannot calculate the value of the elpd since
we do not know the true model $p_t(\tilde y_i)$. \cite{Vehtari2017}
propose several approaches relying on cross-validation to estimate the
elpd with the available dataset; we describe here the \textit{K-fold
  cross validation} approach that we implemented in our study.\\

To implement this approach, we must randomly partition the dataset in
$K$ subsamples. At each step of the cross-validation process, one
subsample is retained as a validation set and the remaining $K-1$
subsamples are pooled together and used as a calibration set. The
model $\mathcal{M}_0$ is then fitted to the calibration set using
MCMC, leading to $S$ vectors $\theta^{s,k}$ randomly drawn from the
posterior distribution $p(\theta|y_{-k}, \mathcal{M}_0)$, with
$y_{-k}$ the calibration dataset obtained after the removal of the
subsample $k$. In other words, $\theta^{s,k}$ is the $\theta$
simulated at the iteration $s$ of the MCMC used to fit the model after
removal of the subsample $k$. Then, for each observation $i$ belonging
to the validation set $k$, we calculate the contribution of the
observation $i$ to the estimated elpd by:
$$
\widehat{\mbox{elpd}}_i(\mathcal{M}_0) = \log \left ( \frac{1}{S} \sum_{s=1}^S
  p(y_i|\theta^{k,s}, \mathcal{M}_0) \right )
$$
with $p(y_i|\theta^{k,s}, \mathcal{M}_0)$ the probability to obtain
the observed value $y_i$, for the parameter vector
$\theta^{s,k}$ generated by the $s$-th MCMC iteration. This
probability can be calculated using the model $\mathcal{M}_0$.\\ 

This operation is repeated on all subsamples $k$, which allows to
estimate the contribution $\widehat{\mbox{elpd}}_i$ to the elpd for
all observations $i$ of the dataset. We can estimate the total elpd
by:
$$
\widehat{\mbox{elpd}}_{\mbox{xval}}(\mathcal{M}_0) = \sum_i
\widehat{\mbox{elpd}}_i(\mathcal{M}_0)
$$
The same operation can be repeated for model $\mathcal{M}_1$, and the
model with the largest value of $widehat{\mbox{elpd}}_{\mbox{xval}}$
is the model with the best predictive efficiency.


\subsection{K-fold cross-validation in our study}
\label{sec:k-fold-cv-study}

Now consider the N-mixture model used to predict the mean number of
capercaillie cocks on leks in our study. This is a hierarchical model,
which raises the question of the ``level'' at which the statistical
unit should be defined to assess the predictive ability of our model
(the census? the set of censuses on a lek during a given year? the
whole set of censuses carried out during all years of the study period
on a given lek? etc.). We must consider the aim of the model to choose
this level appropriately \cite{Merkle2019}.\\

Actually, the estimation of the capercaillie population sizes and
trends strongly relies on our ability to predict the time series of
the number of males on leks not included in the sample. Thus, we must
include \textit{all} censuses carried out on a lek (all censuses and
all years) to the same subsample, and assess the predictive efficiency
at the level of the lek. This approach is the \textit{grouped K-fold
  for leave-one-group out} defined in
\url{https://avehtari.github.io/modelselection/rats_kcv.html}. In
other words, we have $N$ leks (each one being censused one or several
years, with one or several censuses every year), and these $N$ leks
are partitionned in $K$ subsamples of $N/k$ leks.  We partitionned our
dataset in $K=10$ subsamples (\cite{Vehtari2017} indeed recommend to
define at least 10 subsamples in \textit{K-fold
  cross validation} approaches).\\

As described in the previous section, we fitted a model on a
calibration dataset excluding each subsample $k$ in turn. For each
calibration dataset excluding a subsample $k$, we then drew a MCMC
sample of $S$ vectors of parameters $\theta^{k,s}$ containing the top
parameters of the model ($\kappa_{g(i),\ell(i),b(t)}$,
$\sigma_\kappa, \sigma_\epsilon, \sigma_\eta, \sigma_\nu, \alpha_d ,
\beta_d, \sigma_e$).\\

We assess for each lek of the group $k$, the contribution to the elpd
of the set of censuses carried out on lek $i$. Thus, if $\mathbf{y}_i$
is the vector containing the set of censuses carried out on lek $i$
between 2010 and 2019, we need to calculate the probability
$p(\mathbf{y}_i|\theta^{k,s}, \mathcal{M}_0)$ to get this set of censuses
for each vector $\theta^{k,s}$. The contribution of the lek $i$ to the
elpd is calculated by:
$$
\widehat{\mbox{elpd}}_i(\mathcal{M}_0) = \log \left ( \frac{1}{S}
  \sum_{s=1}^S p(\mathbf{y}_i|\theta^{k,s}, \mathcal{M}_0) \right )
$$
And the total elpd is calculated by summing these contributions over
all leks.\\


The calculation of $p(\mathbf{y}_i|\theta^{k,s}, \mathcal{M}_0)$,
required for the calculation of elpd, is a bit tricky. Indeed, it can
be calculated by:
$$
p(\mathbf{y}_i|\theta^{k,s}, \mathcal{M}_0) = \int p(\mathbf{r}_i|
\mathbf{N}_i) \times p(\mathbf{N}_i|\theta^{k,s},
\mathcal{M}_0)d\mathbf{N}_i
$$
with $\mathbf{N}_i$ the vector containing the actual numbers of males
on the lek $i$ for each two-year period. We approximate this integral
by a Monte Carlo approach \cite{Robert2010a}. For each vector
$\theta^{k,s}$ generated by MCMC, we simulated $R = 1000$ vectors
$\mathbf{N}_i^{(r)}$ using our model. For each simulated vector: (i)
we simulated for each a lek effect $\eta_i$, an overdispersion
residual $\epsilon_{ij}$, and possibly a natural unit effect
$\nu_{u(i)}$; (ii) we summed these effects and added the simulated
value of $\kappa_{g(i),\ell(i),b}$ to calculate the value of
$\log \lambda_{it}^{(r)}$; (iii) we randomly sampled $R$ actual
numbers of males $N_{it}^{(r)}$ in a Poisson distribution with
parameter $\lambda_{it}^{(r)}$), and we derived from each vector
$\mathbf{N}_i^{(r)} = \{N_{it}^{(r)}\}_{p=1}^5$ the probability
$p(\mathbf{y}_i| \mathbf{N}_i^{(r)}, \theta^{k,s})$ under our
detection model. The probability
$p(\mathbf{y}_i|\theta^{k,s}, \mathcal{M}_0)$ is then equal to the
mean over all $R$ simulations of these probabilities
$p(\mathbf{y}_i| \mathbf{N}_i^{(r)}, \theta^{k,s})$:
$$
\hat p(\mathbf{y}_i|\theta^{k,s}, \mathcal{M}_0) = \frac{1}{R}
\sum_{r=1}^R p(\mathbf{y}_i| \mathbf{N}_i^{(r)}, \theta^{k,s})
$$
The probability $p(\mathbf{y}_i| \mathbf{N}_i^{(r)}, \theta^{k,s})$ is
calculated by the product of the probabilities $p(y_{itk}|N_{it},
\theta^{k,s})$ over all censuses carried out during our study
period.\\

To sum up, \textit{in theory}, for a given model $\mathcal{M}_0$, the
elpd is calculated by summing the individual contributions
$\widehat{\mbox{elpd}}_i(\mathcal{M}_0) $ over all leks $i$. However,
the number of censuses differs a lot between leks (between 1 to 19
censuses in 10 years). However, the probability to observe a given set
of censuses decreases when the number of censuses increases: for
example, if $p$ is the probability to detect $n$ males during a
census, then the probability to detect $n$ males during each one of
two censuses is $p^2$ if these two censuses are independent. In other
words, the logarithm of the mean of
$p(\mathbf{y}_i|\theta^{k,s}, \mathcal{M}_0)$ over all simulations $s$
is much smaller for leks with many censuses:
these leks have a much larger weight in the calculation the elpd.\\

This problem was not considered in \cite{Vehtari2017} (who focus their
paper on leave-one-out cross-validation, so that there is no
difference in sample size among statistical units in their study). We
propose to complete this first calculation of the elpd with another
approach attempting to correct these unequal weights. As noted before,
the order of magnitude of the probability to observe $n$ events is
$p^n$ if the probability to observe one event is $p$ and if these
events are independent. Therefore, the
log-probability will be equal to $n\log p$.\\

Therefore, \textit{if the $c_i$ censuses carried out on a given lek
  $i$ were independent}, we would expect
$\widehat{\mbox{elpd}}_i(\mathcal{M}_0)$ to decrease linearly with
$c_i$. In such a case, replacing
$\widehat{\mbox{elpd}}_i(\mathcal{M}_0)$ in the calculation of the
elpd with $\widehat{\mbox{elpd}}_i(\mathcal{M}_0)/c_i$ would allow to
give the same weight to all leks in the calculation of the elpd. Let
eldp$^c$ be the elpd ``corrected'' by this approach.\\

However, in our study, the $c_i$ censuses carried out on a given lek
\textit{are not} independent: some censuses are carried out during the
same year and some during different years; some are carried out during
the same period and some during different periods, etc. Therefore,
$c_i$ is an overestimation of the ``effective'' sample size for lek
$i$, and dividing the $\widehat{\mbox{elpd}}_i(\mathcal{M}_0)$ by
$c_i$ will
``over-correct'' the places with the largest number of censuses.\\

Thus, elpd gives too much weight to the big leks in the model
comparison, and elpd$^c$ does not give enough weight to these leks.
However, when these two criteria return the same conclusions, we can
be confident that the selected model is the best one in the set of
compared models.\\

We calculated the contributions to elpd and elpd$^c$ for each model. We
also calculated the standard deviation of the difference between the
elpd/elpd$^c$ of a model $\mathcal{M}_r$ and the elpd/elpd$^c$ of the
best model $\mathcal{M}_b$ in the set. This standard deviation is
calculated by:
$$
\sqrt{\frac{n}{n-1} \sum_{i=1}^n (\Delta_i- \bar{\Delta}_i)^2 }
$$
Where $\Delta_i = \widehat{\mbox{elpd}}_i(\mathcal{M}_r) -
\widehat{\mbox{elpd}}_i(\mathcal{M}_b)$, and $\bar{\Delta}$ is the
mean of the $\Delta_i$. The standard deviation for the elpd$^c$ is
obtained similarly by replacing elpd by elpd$^c$ in the above
formula.\\

Finally, we carried out a randomization test to determine if the elpd
of a model was significantly different from the elpd of the best
model. We used the following test criterion:
$$
T = \sum_i \Delta_i
$$
which is the difference between the elpd of the model and the elpd of
the best model. We then carried out a randomization test, changing
randomly the sign of the $\Delta_i$'s and calculating again the
criterion. We repeated this randomization 1000 times, and calculated
the proportion of simulated values for $T$ greater than the observed
value. 



\subsection{Implementation in R}
\label{sec:implementation-r}


The K-fold cross validation approach is implemented in the function
\texttt{kfoldCVModelCount}. Our dataset contains 330 leks, so that we
define a partition of 10 groups of 33 leks:

<<>>=
set.seed(980)
ooo <- sample(c(rep(1:10,each=33)))
@ 

Then, we can use the function \texttt{kfoldCVModelCount} to implement
cross-validation. We illustrate the process below for the model
\texttt{modelCountDetectBinREY} used in our paper. WARNING!!! THIS
CALCULATION CAN TAKE SEVERAL HOURS. Note that we have included the
results of this calculation as a dataset of the package, so that the
reader does not need to launch this function to reproduce further
calculations:

<<eval=FALSE>>=
listCoefsCVBinREY <- kfoldCVModelCount(ooo, dataList, "modelCountDetectBinREY")
@ 

The resulting object \texttt{listCoefsCVBinREY} is a list containing
the values of the coefficients sampled by MCMC by excluding each
subsample of leks in turn (the first element of the list contains the
coefficients sampled by MCMC when fitting the model on a dataset
excluding the group 1 of lek, etc.). We can then use the function
\texttt{LLCount} to calculate the matrix containing the probabilities
$p(\mathbf{y}_i| \mathbf{N}_i^{(r)}, \theta^{k,s})$ to observe the set
of detected males during all censuses for a given lek (rows) under the
model with a given sampled vector of parameters (columns). WARNING,
this calculation can also be very long. The result of this calculation
is also available as a dataset in the package:

<<eval=FALSE>>=
llcBinREY <- LLCount(dataList, listCoefsCVBinREY, ooo)
@ 

Finally, we can calculate the contribution of each lek to the elpd:

<<>>=
elpdBinREY <- elpdLeks(llcBinREY)
@

The same approach is used for other models. Note that because the
lists of coefficients sampled by MCMC returned by the function
\texttt{kfoldCVModelCount} are very large objects ($>$ 40 MB), we do
not include such objects for other models in our package. However, the
result of the function \texttt{LLCount} is presented for all of
them. For the record, the code used to obtain such object, WHICH TAKES
SEVERAL DAYS OF COMPUTING, is presented below. The resulting objects
(with names starting by \texttt{llc}) are stored as datasets of the
package:

<<eval=FALSE>>=
## K-fold CV for different models
listCoefsCVBin <- kfoldCVModelCount(ooo, dataList, "modelCountDetectBin")
listCoefsCVBinREYObs2 <- kfoldCVModelCount(ooo, dataList, "modelCountDetectBinREYObs2")
listCoefsCVBetaBinREY <- kfoldCVModelCount(ooo, dataList, "modelCountDetectBetaBinREY")

## The list
llcBin <- LLCount(dataList, listCoefsCVBinREY, ooo)
llcBinREYObs2 <- LLCount(dataList, listCoefsCVBinREY, ooo)
llcBetaBinREY <- LLCount(dataList, listCoefsCVBinREY, ooo)
@ 

We then carry out the same approach with the model
\texttt{modelCountDetectBin}, considering yearly periods instead of
two-years periods. We need to prepare the data again to test this
model: 

<<>>=
dataList2 <- dataCount2jags(lekcounts$lek, lekcounts$year,
                            lekcounts$nbobs, lekcounts$nbmales,
                            lekcounts$gr, as.numeric(factor(lekcounts$type)),
                            lekcounts$natun, lekcounts$year)
@ 

And we carry out the same approach for this model:

<<eval=FALSE>>=
listCoefsCVBinPerYear <- kfoldCVModelCount(ooo, dataList2, "modelCountDetectBin")
llcBinPerYear <- LLCount(dataList2, listCoefsCVBinPerYear, ooo)
@ 

We derive the contribution of each lek to the elpd of each model:

<<>>=
elpdBin <- elpdLeks(llcBin)
elpdBinREYObs2 <- elpdLeks(llcBinREYObs2)
elpdBetaBinREY <- elpdLeks(llcBetaBinREY)
elpdBinPerYear <- elpdLeks(llcBinPerYear)
@

And we also calculate the contributions to the ``corrected'' elpd for
each model:

<<>>=
## Number of censuses for each lek
cidl <- tapply(dataList$repetition, dataList$lek, sum)
cidl2 <- tapply(dataList2$repetition, dataList2$lek, sum)

## corrected contribution
elpdcBinREY <- elpdBinREY/cidl
elpdcBin <- elpdBin/cidl
elpdcBinREYObs2 <- elpdBinREYObs2/cidl
elpdcBetaBinREY <- elpdBetaBinREY/cidl
elpdcBinPerYear <- elpdBinPerYear/cidl
@ 


Finally, we calculated the elpd/elpdc, the standard deviation for each
model of their difference with the best model, and we performed the
randomization test for each criterion:


<<>>=
## ELPD 
## Randomization test
library(ade4)
pv <- sapply(list(elpdBin, elpdBinREY, elpdBinREYObs2, elpdBetaBinREY,
            elpdBinPerYear), function(x) {
    
    sim <- sapply(1:1000, function(i)
        sum(sample(c(-1,1), length(elpdBinREY),
                   replace=TRUE)*(elpdBinREY-x)))
    obs <- sum(elpdBinREY-x)
    as.randtest(sim,obs)$pvalue
})

## criterion elpd
elpds <- c(sum(elpdBin),sum(elpdBinREY),
                  sum(elpdBinREYObs2),sum(elpdBetaBinREY),
           sum(elpdBinPerYear))

## SD difference with the best model
elpdDiffsd <- sqrt(length(elpdBin))*c(sd(elpdBin-elpdBinREY),
                                  0, sd(elpdBinREYObs2-elpdBinREY),
                                  sd(elpdBetaBinREY-elpdBinREY),
                                  sd(elpdBinPerYear-elpdBinREY))


## "Corrected" ELPD 
## Randomization test
pvc <- sapply(list(elpdcBin, elpdcBinREY, elpdcBinREYObs2, elpdcBetaBinREY,
                  elpdcBinPerYear), function(x) {
    
    sim <- sapply(1:1000, function(i)
        sum(sample(c(-1,1), length(elpdBinREY),
                   replace=TRUE)*(elpdcBinREY-x)))
    obs <- sum(elpdcBinREY-x)
    as.randtest(sim,obs)$pvalue
})

## criterion
elpdcs <- c(sum(elpdcBin),sum(elpdcBinREY),
            sum(elpdcBinREYObs2),sum(elpdcBetaBinREY),
            sum(elpdcBinPerYear))

## SD Difference with the best model
elpdcDiffsd <- sqrt(length(elpdcBin))*c(sd(elpdcBin-elpdcBinREY),
                                        0, sd(elpdcBinREYObs2-elpdcBinREY),
                                        sd(elpdcBetaBinREY-elpdcBinREY),
                                        sd(elpdcBinPerYear-elpdcBinREY))


## Data.frame containing the result for elpd
dfelpd <- data.frame(Model=c("modelCountDetectBin","modelCountDetectBinREY",
                             "modelCountDetectBinREYObs2",
                             "modelCountDetectBetaBinREY",
                             "modelCountDetectBin per year"),
                     elpd=elpds,
                     SDDiff=elpdDiffsd,
                     Pvalue=round(pv,3))


## for elpdc
dfelpdc <- data.frame(Model=c("modelCountDetectBin","modelCountDetectBinREY",
                              "modelCountDetectBinREYObs2",
                              "modelCountDetectBetaBinREY",
                              "modelCountDetectBin per year"),
                      elpdc=elpdcs,
                      SDDiffc=elpdcDiffsd,
                      Pvalue=round(pvc,3))

@ 



\subsection{Discussion}
\label{sec:discussion}

We now interpret the results of the model comparison. We first
interpret the ``classical'' elpd:

<<>>=
dfelpd
@ 

Here, for each model, we present the estimated elpd (the closer to 0 =
the better), the standard deviation of the difference between the elpd
of each model and the elpd of the best model (therefore equal to 0 for
the best model), and the proportion of simulated differences greater
than or equal to the observed difference between the elpd of a model
and the elpd of the best model.\\

The model used in the paper (binomial distribution with the logit of
the detection probability modeled as a linear effect of the number of
observers + a year random effect) is the best model in the set
according to the elpd. Note that adding a quadratic effect of the
number of observers or supposing an extra-binomial variation in the
detection probability did not lead to a significant improvement of the
prediction. However, removing the random effects of the years from the
detection model led to a decrease of the elpd. Moreover, estimating
one number of males in each region using one year-periods led to a
strong decrease of the elpd. Clearly, our choice to consider two-year
periods is a better one.\\

The same conclusions are reached when working on the ``corrected''
elpd:


<<>>=
dfelpdc
@ 




\section{The lek \# 281}
\label{sec:lek--281}

We have seen in the section \ref{sec:goodness-fit} that the lek \# 281
was characterized by a very large residual in our model. This lek is a
UL discovered by the grid cell searches carried out in 2013, and it is
characterized by a very large number of detected animals (the two
censuses carried out on this lek resulted in 18 and 17
males respectively).\\

The examination of the quantile plot of the contributions of each lek
to the corrected elpd shows that the lek 281 contributes significantly
to the elpd:

<<>>=
plot(c(1:length(elpdcBinREY))/length(elpdcBinREY),
     sort(elpdcBinREY), xlab="Quantile",
     ylab="Contributions to elpdc")
text(0.05, -8.71, "Lek 281")
@ 

Other state models that we have tried during previous years on this
dataset identify the same problem: this lek is an outlier
characterized by a much larger number of detected males than other
ULs. Since the number of detected ULs is low (32
leks), any outlier will have a strong effect on the inference.\\

We wanted to assess more precisely the effect of this lek on our
inference, by trying to fit the model again without this lek, and by
estimating again the number of males in each region. WARNING: THIS
CALCULATION TAKES A VERY LONG TIME (several hours)!!!! Fortunately, the
package contains the result \texttt{coefModelm281} of the fit as a
dataset in the package:

<<eval=FALSE>>=
lcb <- lekcounts %>% filter(lek!=281)
lcb$lek <- as.numeric(factor(lcb$lek))
dataListwo281 <- dataCount2jags(lcb$lek, lcb$period,
                                lcb$nbobs, lcb$nbmales,
                                lcb$gr, as.numeric(factor(lcb$type)),
                                lcb$natun, lcb$year)

coefModelm281 <- fitModelCount(dataListwo281, "modelCountDetectBinREY")
@ 

We then estimate the number of males in each region with this new
model:

<<>>=
nmwo281 <- estimateNmales(coefModelm281, coefModelULPresence,
                          gridFrame, NKAL, NKIL)
summary(nmwo281)
@ 

We recall the estimates of our model:


<<>>=
summary(nm)
@ 

Removing this lek from the dataset results in a decrease of the
estimated population size of about 70 to 100 males, i.e. about a
5\% decrease in the population size estimated for the whole mountain
range. Note that the lek 281 was located in the geographical region 1
and discovered in period 2, so that we could expect a larger effect of
this lek in this region during this period. We compare  the estimates
of region 1 with this lek...


<<>>=
summary(nm,1)
@ 

...and without this lek:


<<>>=
summary(nmwo281,1)
@ 

The removal of this lek from the dataset results in a decrease of the
estimated population size in this region of about 10 males, i.e. about
a 6.5\% decrease in the population size. Actually, this lek has a
strong effect on the estimation of the number of males, has the same
effect in all regions. Actually, the estimates of the random effects
$\kappa_{g(i),\ell(i),b(t)}$, which represent how the median number of
males on a lek varies across regions and periods, are very similar
whether we remove lek 281 or not:

<<fig.width=10, fig.height=5, out.width='\\linewidth',out.height='0.5\\linewidth'>>=
library(matrixStats)
kap <- MCMCchains(coefModelm281, "kappa")
kapb <- MCMCchains(coefModelCountDetectBinREY, "kappa")
par(mfrow=c(1,2))
cmbk <- colMeans(kapb)
cmbv <- colVars(kapb)
cmk <- colMeans(kap)
cmv <- colVars(kap)

## Remove the "virtual levels" included in the model to have
## a square matrix region x period x types of leks
## (we included these levels because we do not have the
## same number of regions for all types of lek)
cmbk <- cmbk[cmv<8]
cmbv <- cmbv[cmv<8]
cmk <- cmk[cmv<8]
cmv <- cmv[cmv<8]


plot(cmbk, cmk, xlab="Point estimate of kappa with 281",
     ylab="Point estimate of kappa without 281")
plot(cmbv, cmv, xlab="SD of kappa distribution with 281",
     ylab="SD of kappa distribution without 281") 
@ 

Actually, this lek increases the estimate of the variance of the lek
random effects:

<<>>=
set <- 1/MCMCchains(coefModelm281, "sigmaeta")
setb <- 1/MCMCchains(coefModelCountDetectBinREY, "sigmaeta")
colnames(setb) <- c("KAL","KIL","UL")
colnames(set) <- paste0(c("KAL","KIL","UL"),"/wo281")
setg <- cbind(setb,set)[,c(1,4,2,5,3,6)]
boxplot(setg, cex.axis=0.9, ylab="Posterior distr. on variance of the lek random effects")
@ 

The estimated variance for ULs is much smaller when the lek
281 is removed. Examination of other parameters show that
adding/removing census data of the lek \# 281 does not change the
posterior distribution. \\

Removing this lek from our dataset would lead to a decrease of about
5\% of our population size estimate. We have no reason to exclude this
lek, as it has been discovered by our protocol, and actually
``represents'' other ULs of similar size, which -- although they are
probably not very frequent in the mountain range -- do exist but are
not yet discovered. Today, as the number of ULs detected during grid
cells searches is small, any big lek will have a strong effect on the
inference, which is what we show here. Today, this lek is an outlier,
and as such, has a significant effect on our inference, though not
that strong (probably less than 5\%). But as more and more data on ULs
will be collected in the future, the weight of this lek on our
estimate will decrease and we will have a finer understanding of the
distribution of the number of males on ULs.


\section{Sensitivity of our model to the violation of several hypotheses}
\label{sec:sens-our-model}

\subsection{Criticisms of \cite{Link2018} and \cite{Barker2017}}
\label{sec:crit-citel-citeb}

Two recent papers by \cite{Link2018} and \cite{Barker2017} identified
many problems with N-mixture models that can strongly affect the
population size estimation by these models. In this section, we review
the criticisms by these authors about N-mixture models to consider
whether they apply to our model. These authors consider the inference
of abundance $N$ drawn from a Poisson distribution and a binomial
detection process
characterized by a detection probability $p$.\\

First, \cite{Barker2017} suggests that in some studies, the abundance
$N$ may not exist as a parameter. We understand that this situation
may occur in some studies, e.g. in some point count studies where the
area delimited by a ``site'' may not be clearly defined. However, in
our study, we suppose that each capercaillie cock of the mountain
range is located on only one lek. Therefore, the set of leks can be
considered as a contraction of the space used by capercaillie cocks,
and the abundance
does exist as a parameter for each lek.\\

Another issue arises when the detection probability $p\rightarrow 0$;
in this case the binomial distribution describing the detection
process converges towards a Poisson distribution with parameter
$\lambda = Np$. In other words, the parameters $N$ and $p$ are not
separable when $p$ is small, making the inference on $N$ alone
difficult. However, in our study, the cock detection probability was
estimated to be of $\approx$ 0.6, so that this issue is not a concern
in our study.\\

Actually, the most serious criticisms by these authors concern the
effect of unaccounted variation in detection probability. These
authors show, in the case of a state model corresponding to a simple
Poisson distribution that even a small amount of unaccounted variation
can lead to a considerable bias in the estimation of $N$. They show
the same problem with accidental double counting. Thus,
\cite{Link2018} note: ``\textit{2\% rate of double counts or a
  standard deviation of 2\% in detection rates might seem
  insubstantial, but each is large enough to produce $>$20\% bias in
  estimation of mean abundance}''. This is a worrying result, as no
model could ascertain that the amount of unaccounted variation in the
detection process is so small. In the next two sections, we carry out
some simulations to test the effect of unaccounted variation in
detection probability and accidental double counting on the estimation
of the number of males.



\subsection{Unaccounted variation in detection probability}
\label{sec:unacc-vari-detect}

\subsubsection{Simulation of both the state and detection process}
\label{sec:simul-whole-proc}

We tested the effect of unaccounted variation in detection probability
on the estimation of the number of males in the whole mountain
range. We used the model fitted in section \ref{sec:fitmc} to generate
new datasets (i.e. simulating the state process, and then the
detection process), adding a level of unaccounted variation in the
detection probability. More precisely, we used the same state model as
the one used in the paper to generate numbers of males on the sampled
leks. We also used the same model to simulate the \textit{average}
probability of detection for each census. For the census $k$ of year
$t$ on lek $i$, this average probability is $d_{i,t,k}$ and the actual
probability is supposed to be drawn from a beta distribution:
$$
p_{i,t,k}  \sim \mbox{Beta}\left( d_{i,t,k} \times
                   \frac{1-\delta^2}{\delta^2}, (1-d_{i,t,k}) \times
                   \frac{1-\delta^2}{\delta^2} \right )
$$
The parameter $\delta^2$ controls the amount of extra-binomial
variation added to the detection process. We considered the followwing
values for the parameter $\delta^2$:


<<>>=
delta2b <- c(0, 0.001, 0.005, 0.01, 0.05, 0.1, 0.3)
@ 

For each value of $\delta^2$, we simulated 10 datasets, and we
estimated the posterior distribution of the number of males. We used
the function \texttt{simulateDataList}, included in the package to
simulate this data generating process. We then calculated the median
of this distribution. WARNING!!! THIS CALCULATION TAKES A VERY LONG
TIME (several hours)!!!! Fortunately, the package contains the result
\texttt{medianNmalesBB} of this calculation (matrix with 10 columns
-- the 10 repetitions -- and 7 rows -- the 7 values of $\delta^2$ --
containing the median of the posterior distributions):


<<eval=FALSE>>=
libtt <- list()

for (j in 1:10) {
    cat("###########################",
        "\n###########################",
        "\n###########################",
        "\n###########################",
        "\n### Iteration", j,"\n\n\n")
    liresuBeta <- list()
    for (i in 1:7) {
        cat("###########################\n### Model", i,"\n\n\n")
        if (i!=1) {
            sdl <- simulateDataList(coefModelCountDetectBinREY,
                                    dataList, betaBinDelta=delta2b[i])
        } else {
            sdl <- simulateDataList(coefModelCountDetectBinREY, dataList)
        }
        fm <- fitModelCount(sdl, "modelCountDetectBinREY", n.iter=30000, thin=30)
        liresuBeta[[i]] <- list(dataList=sdl, coefs=fm)
        saveRDS(liresuBeta, file="liresuBeta.Rds")
    }
    libtt[[j]] <- liresuBeta
    saveRDS(libtt, file="libtt.Rds")
}


listNmalesBB <- lapply(libtt, function(liresuBeta)
    lapply(liresuBeta, function(x)
        estimateNmales(x$coefs, coefModelULPresence, gridFrame, NKAL, NKIL)))

medianNmalesBB <- sapply(listNmalesBB, function(z)
    sapply(z, function(x) median(getTotal(x)[,1])))
@ 


We present below how the median of the estimated posterior
distribution on the number of males for the reference period 2010-2011
in the whole mountain range varies with the proportion of unaccounted
variation. As the estimated detection probability in our study is
about 0.6, we calculated the coefficient of variation of a beta
distribution of the average detection probabilities was equal to 0.6,
for each value of $\delta^2$. This allowed to display the relationship
between the proportion of unaccounted variation and the estimated
number of males:


<<>>=
## coefficient of variation
coefvar <- c(0,sapply(delta2b[-1], function(delta2) {
    alpha <- 0.6*(1-delta2)/delta2
    beta <- 0.4*(1-delta2)/delta2
    sqrt(alpha*beta/((alpha+beta)^2 * (alpha+beta+1)))/0.6
}))


plot(rep(coefvar, 10),as.vector(medianNmalesBB),
     xlab="% of unaccounted variation in detection proba",
     ylab="Estimated number of males in 2010-2011")
xy <- data.frame(x=rep(coefvar, 10), y=as.vector(medianNmalesBB))
xv <- seq(0,0.5,length=200)
lines(xv, predict(lm(y~x+I(x^2), data=xy), newdata=data.frame(x=xv)), col="red")
@ 


The case $\delta^2 = 0$ corresponds to zero unaccounted extra-binomial
variation. Note that the overestimation in the number of males is not
linearly related to the coefficient of variation of the detection probability.\\

Although increasing the amount of unaccounted variation in the
detection probability indeed results in an increase in the estimated
number of males, our model seems quite robust to this source of bias:
even with $\sim$ 10\% of unexplained variability in the detection
probability, the resulting bias is nearly unnoticeable in comparison
to the imprecision of our estimation.\\


\subsubsection{Simulating the detection process only}
\label{sec:simul-detect-proc}

In the previous section, we have assessed the effect of unaccounted
heterogeneity in the detection process on the estimation of the number
of males by simulating the whole process (both the state process
generating the true number of males on sampled leks, and the detection
process), while adding a certain amount of unaccounted variability in
the process. However, since we are working on unaccounted variation in
detection probability, it would be interesting to keep the true number
of males fixed in our simulations while varying the amount of
unaccounted variation in detection probability.\\

We used the function \texttt{simulateN}  to simulate the true number
of males present on the sampled leks/periods.

<<>>=
set.seed(1)
simn <- simulateN(coefModelCountDetectBinREY,dataList)
@ 

Then, for this particular simulated true number of males, we simulated
the detection process with various levels of unaccounted detection
probability. WARNING!!! THIS CALCULATION TAKES A VERY LONG TIME
(several hours)!!!! Fortunately, the package contains the result
\texttt{medianNmalesBB2} of this calculation (matrix with 10 columns
-- the 10 repetitions -- and 5 rows -- the 5 values of $h$ --
containing the median of the posterior distributions):


<<tentative-n-fixe, eval=FALSE>>=
delta2b <- c(0, 0.004, 0.015, 0.05, 0.1, 0.2)
libtt2 <- list()
for (j in 1:10) {
    cat("###########################",
        "\n###########################",
        "\n###########################",
        "\n###########################",
        "\n### Iteration", j,"\n\n\n")
    liresuBeta <- list()
    for (i in 1:6) {
        cat("###########################\n### Model", i,"\n\n\n")
        if (i!=1) {
            sdl <- simulateDataList2(coefModelCountDetectBinREY,dataList,
                                     simn, betaBinDelta=delta2b[i])
        } else {
            sdl <- simulateDataList2(coefModelCountDetectBinREY,
                                     dataList, simn)
        }
        fm <- fitModelCount(sdl, "modelCountDetectBinREY", n.iter=10000, thin=10)
        liresuBeta[[i]] <- list(dataList=sdl, coefs=fm)
    }
    libtt2[[j]] <- liresuBeta
    saveRDS(libtt2, file="libtt2.Rds")
}


listNmalesBB2 <- lapply(libtt2, function(liresuBeta)
    lapply(liresuBeta, function(x)
        estimateNmales(x$coefs, coefModelULPresence,
                       gridFrame, NKAL, NKIL)))

medianNmalesBB2 <- sapply(listNmalesBB2, function(z)
    sapply(z, function(x) mean(getTotal(x)[,1])))
save(medianNmalesBB2, file="medianNmalesBB2.rda")

@ 


We show below how the median of the estimated posterior distribution
on the number of males for the reference period 2010-2011 in the whole
mountain range varies with the coefficient of variation of the
detection probability when this probability is equal to 0.6:

<<>>=
delta2b <- c(0, 0.004, 0.015, 0.05, 0.1, 0.2)

## coefficient of variation
coefvar <- c(0,sapply(delta2b[-1], function(delta2) {
    alpha <- 0.6*(1-delta2)/delta2
    beta <- 0.4*(1-delta2)/delta2
    sqrt(alpha*beta/((alpha+beta)^2 * (alpha+beta+1)))/0.6
}))


plot(rep(coefvar, 10),as.vector(medianNmalesBB2),
     xlab="% of unaccounted variation in detection proba",
     ylab="Estimated number of males in 2010-2011")
xy <- data.frame(x=rep(coefvar, 10), y=as.vector(medianNmalesBB2))
xv <- seq(0,0.5,length=200)
lines(xv, predict(lm(y~x+I(x^2), data=xy), newdata=data.frame(x=xv)), col="red")
@ 


Keeping fixed the actual number of males while varying the unaccounted
variation in detection probability does not change the results
obtained in the previous section. The effect of unaccounted variation
in detection probability is unnoticeable when the coefficient of
variation of this probability is $<$15\%. When this coefficient of
variation reaches 25\%, this results in a point estimate of $\sim$
2200 males instead of $\sim$ 1900,
i.e. (2200-1900)/1900 $\approx$ 15\% overestimate.\\

This result is very different from the 20\% bias in estimated number
of males resulting from the 2\% unaccounted variation in
\cite{Link2018}. Actually, these authors considered a very simple
Poisson state model: with their simple model, any unaccounted
heterogeneity in detection probability will result in an increase of
the estimated Poisson parameter. Our model is more complex, with many
random effects accounting for the hierarchical structure of the state
process: the unaccounted heterogeneity in detection probability is
likely absorbed by the various random effects of the state model,
which limits this effect.\\

In conclusion, the unaccounted heterogeneity in detection process is
unlikely to strongly affect our inference.



\subsection{Effect of accidental double counting}
\label{sec:effect-double-counts}


\subsubsection{Simulation of both the state and detection process}
\label{sec:simul-whole-proc-double}

We also tested the effect of accidental double counting on our
estimation. As for the assessment of the effect of unaccounted
heterogeneity, we first generated datasets by simulating the state
process, and then the detection process. We also used the model fitted
in section \ref{sec:fitmc} to generate new datasets, but this time, we
added a random proportion of animals counted twice to the simulated
censuses. More precisely, we used the same state model as the one used
in the paper to generate numbers of males on the sampled leks. We also
used the same model to simulate the probability of detection for each
census. If $y_{i,t,k}$ is the number of distinct males detected on lek
$i$ during census $k$ of year $t$, then we suppose that the
number of animals counted twice during this census is randomly drawn
from a Binomial distribution $\mathcal{B}(y_{i,t,k}, h)$, where $h$ is
the proportion of animals counted twice. We tested the following
values of $h$:

<<>>=
doubleCountspb <- c(0.05, 0.1, 0.2, 0.3, 0.5)
@ 


For each value of $h$, we simulated 10 datasets, and we estimated
the posterior distribution of the number of males. We again used the
function \texttt{simulateDataList}, included in the package to
simulate this data generating process. We then calculated the median
of this distribution. WARNING!!! THIS CALCULATION TAKES A VERY LONG
TIME (several hours)!!!! Fortunately, the package contains the result
\texttt{medianNmalesBB} of this calculation (matrix with 10 columns
-- the 10 repetitions -- and 5 rows -- the 5 values of $h$ --
containing the median of the posterior distributions):

<<eval=FALSE>>=
lidtt <- list()
for (j in 1:10) {
    cat("###########################",
        "\n###########################",
        "\n###########################",
        "\n###########################",
        "\n### Iteration", j,"\n\n\n")
    liresudc <- list()
    for (i in 1:5) {
        cat("###########################\n### Model", i,"\n\n\n")
        sdl <- simulateDataList(coefModelCountDetectBinREY, dataList,
                                doubleCountsp=doubleCountspb[i])
        fm <- fitModelCount(sdl, "modelCountDetectBinREY", n.iter=30000, thin=30)
        liresudc[[i]] <- list(dataList=sdl, coefs=fm)
        saveRDS(liresudc, file="liresudc.Rds")
    }
    lidtt[[j]] <- liresudc
    saveRDS(lidtt, file="lidtt.Rds")
}

listNmalesDC <- lapply(lidtt, function(liresudc)
    lapply(liresudc, function(x)
        estimateNmales(x$coefs, coefModelULPresence, gridFrame, NKAL, NKIL)))

medianNmalesDC <- sapply(listNmalesDC,
                         function(z)
    sapply(z, function(x) median(getTotal(x)[,1])))
@ 


We present below how the median of the estimated posterior
distribution on the number of males for the reference period 2010-2011
in the whole mountain range varies with the proportion of accidental
double counting:

<<>>=
## Add the case where h=0 (simulated in the previous section)
plot(rep(c(0,doubleCountspb), 10),
     as.vector(rbind(medianNmalesBB[1,], medianNmalesDC)),
     xlab="Proportion of detected bird counted twice",
     ylab="Estimated number of males")
xy <- data.frame(x=rep(c(0,doubleCountspb), 10),
                 y=as.vector(rbind(medianNmalesBB[1,], medianNmalesDC)))
xv <- seq(0,0.5,length=200)
lines(xv, predict(lm(y~x, data=xy), newdata=data.frame(x=xv)), col="red")

@ 

Accidental double counting has a much stronger effect on the
estimation than unaccounted variation in detection
probability. Indeed, even a moderate average proportion of 10\% of
detected animals counted twice results in an estimate of about 2550
animals (instead of the average 1900 obtained in this set of
simulations). This corresponds to an overestimation of $\sim$ 34\%. We
therefore confirm the results of \cite{Link2018} here.


\subsubsection{Simulating the detection process only}
\label{sec:simul-detect-proc-double}

In the previous section, we have assessed the effect of accidental
double counting on the estimation of the number of males by simulating
the whole process (both the state process generating the true number
of males on sampled leks, and the detection process), while adding a
certain number of males counted twice. However, again, we are working
on the detection process so that it would be interesting to keep the
true number of males fixed in our simulations while varying the
proportion of detected males counted twice.\\

We used the same vector \texttt{simn} of true number of males
simulated in section \ref{sec:simul-detect-proc} as the ``true'' state
of the system, and for this particular simulated true number of males,
we simulated the detection process with various levels of accidental
double counting. WARNING!!! THIS CALCULATION TAKES A VERY LONG TIME
(several hours)!!!! Fortunately, the package contains the result
\texttt{medianNmalesDC2} of this calculation (matrix with 10 columns
-- the 10 repetitions -- and 5 rows -- the 5 values of $h$ --
containing the median of the posterior distributions):


<<eval=FALSE>>=
doubleCountspb <- c(0.05, 0.1, 0.2, 0.3, 0.5)

lidtt2 <- list()
for (j in 1:10) {
    cat("###########################",
        "\n###########################",
        "\n###########################",
        "\n###########################",
        "\n### Iteration", j,"\n\n\n")
    liresudc <- list()
    for (i in 1:5) {
        cat("###########################\n### Model", i,"\n\n\n")
        sdl <- simulateDataList2(coefModelCountDetectBinREY,dataList, simn,
                                doubleCountsp=doubleCountspb[i])
        fm <- fitModelCount(sdl, "modelCountDetectBinREY", n.iter=10000, thin=10)
        liresudc[[i]] <- list(dataList=sdl, coefs=fm)
        saveRDS(liresudc, file="liresudc.Rds")
    }
    lidtt2[[j]] <- liresudc
    saveRDS(lidtt2, file="lidtt2.Rds")
}


listNmalesDC2 <- lapply(lidtt2, function(liresuBeta)
    lapply(liresuBeta, function(x)
        estimateNmales(x$coefs, coefModelULPresence, gridFrame, NKAL, NKIL)))

medianNmalesDC2 <- sapply(listNmalesDC2, function(z)
    sapply(z, function(x) mean(getTotal(x)[,1])))
@ 



We show below how the median of the estimated posterior distribution
on the number of males for the reference period 2010-2011 in the whole
mountain range varies with the proportion of accidental double
counting:

<<>>=
doubleCountspb <- c(0.05, 0.1, 0.2, 0.3, 0.5)

## Note that we add the case where h=0 (simulated in the previous section)
plot(rep(c(0,doubleCountspb), 10),
     as.vector(rbind(medianNmalesBB2[1,], medianNmalesDC2)),
     xlab="Proportion of detected bird counted twice",
     ylab="Estimated number of males")
xy <- data.frame(x=rep(c(0,doubleCountspb), 10),
                 y=as.vector(rbind(medianNmalesBB2[1,], medianNmalesDC2)))
xv <- seq(0,0.5,length=200)
lines(xv, predict(lm(y~x, data=xy), newdata=data.frame(x=xv)), col="red")
@ 

Keeping fixed the actual number of males while varying the probability
that a detected male was counted twice does not change the results
obtained in the previous section. Even a moderate average proportion
of 10\% of detected animals counted twice results in an estimate of
about 2750 animals (instead of the average 1900 obtained for a zero
proportion). This corresponds to an overestimation of
$\sim$ 45\%.\\

In conclusion, the unaccounted double counting during censuses can
have a very strong effect on our estimation.



\section{History of the program}
\label{sec:history-program}

The original sampling design was developed in 2009, and we first
applied it during the period 2010--2011. Our initial aim was to
estimate the true number of males at different spatial scales over the
mountain range, the smaller scale being the natural unit. For this
reason, we initially decided to stratify the sampling of both grid
cells for cell searchs and known leks for censuses by natural
unit. First, a sample of natural units was drawn. The sample of
KILs/KALs and grid cells were sampled in those natural units. The same
sample of natural units were monitored for the first three periods, so
that at the end of the third period, all the grid cells of those units
had been searched for new ULs. For the fourth period, a new sample of
natural units was drawn (partially matching the previously sampled
NUs, to allow a longitudinal monitoring
at least for some leks).\\

After the first application in 2010--2011, only 6 new ULs were
discovered following the searches carried out in 77 grid cells carried
out this year. Thus, despite a substantial field work, the number of
discovered ULs was to small to allow the fit of a statistical
distribution of the true number of males present on ULs. We therefore
made the assumption that the number of males on UL had a statistical
distribution similar to the number of males on KILs. Indeed:\\

\begin{itemize}
\item We thought at that time that most large leks on the mountain
  range had already been discovered and were already registered as
  KALs in our sampling frame. Thus, we expected that discovered ULs
  were small leks that appeared recently on the mountain range,
  probably characterized by a tendency to increase. In other words, we
  expected that ULs had a behavior similar to KILs.\\

\item The discovered ULs were indeed characterized by a small number
  of detected males (four leks with one detected male and one lek with
  three detected males), which seemed to confirm this assumption.\\

\item One of the ``discovered'' ULs was actually already known by the
  observers before the sampling. It was a small lek that was known but
  which had never been censused. However the observer had forgotten to
  report it to the program managers prior to the definition of the
  sampling design in 2009. In other words, this UL shared all
  characteristics of a KIL.\\

\item None of the goodness of fit tests carried out at that time
  seemed to indicate that we were wrong in making the assumption that
  ULs and KILs were behaving similarly.\\   
\end{itemize}

However, with time, the number of ULs discovered after grid cell
searchs increased, and after the period 4 (in 2017), we realized that
this assumption did not hold. In particular, the true number of males
was much larger on ULs than on KILs. This matched the impression of
some partners of the program that this number was probably
underestimated.\\

We therefore decided to fit a separate statistical distribution for
the number of males on ULs after period 4. This had the unfortunate
consequence to increase the uncertainty of our estimation. Indeed, by
essence, the category of ULs is not well known, and only a small
number of them is censused every year (although this number is
increasing after each period). The uncertainty on the estimated number
of males on all ULs results from the fact that we need to estimate
both the number of ULs and the distribution of the true number of
males on ULs. Since, by definition, none of these components were
known at the onset of the program, the total number of males present
on ULs is the most uncertain quantity in our model. Separating the ULs
and KILs led to a much higher imprecision of the estimates of the
total number of males, since it implied that the proportion of the
population present in a badly known compartment of
the population was larger than previously imagined.\\

As a result, we changed our sampling approach of grid cells. The only
way to decrease uncertainty was to put a maximum effort in the
discovery of new ULs. We then increased the effort put in grid cell
searches for the period 2018--2019. Moreover, we modified the sampling
design to increase the probability that a grid cell search result into
the discovery of new ULs. We stopped to restrain our sampling to a
small set of natural units, and sampled grid cells among all grid
cells of a geographic region instead.\\

We used a map of the area of potential capercaillie presence defined
by a group of experts in 2009, before the onset of the program as a
guide to select grid cells. We sampled the grid cells to be searched
with a probability proportional to the proportion of the cells covered
by the area of capercaillie potential presence. Moreover, we decided
to no longer stratify the grid cells by natural units: it appeared
that there were no clear differences of the probability of presence of
UL between the natural units. Avoiding this stratification allowed to
sample grid cells over the whole mountain range and thereby maximize
the probability to find new ULs in sampled grid cells.\\

However, between 2010 and 2017, many ULs discovered by the network of
observers outside the monitoring framework (e.g. resulting either from
accidental discovery, from compilation of local knowledge, or from
local initiatives leading to the search for new leks) were reported to
the program managers. When a sampled grid cell contained such an UL,
no search was organised for this cell, and the presence of an UL was
reported. Our model differenciates these ULs from the ULs discovered
following grid cells.





\begin{thebibliography}{9}
\bibitem[BAR17]{Barker2017}
  Barker, R. J.; Schofield, M. R.; Link, W. A. \& Sauer, J. R. 2018. On
  the reliability of N-mixture models for count
  data. \textit{Biometrics}, 74, 369-377.

\bibitem[GAR00]{Garrett2000}
  Garrett, E.S. \& Zeger, E.L. 2000. Latent class model
  diagnosis. \textit{Biometrics}, 56, 1055--1067.
  
\bibitem[LIN18]{Link2018} 
  Link, W. A.; Schofield, M. R.; Barker, R. J. \& Sauer, J. R. 2018. On
  the robustness of N-mixture models. \textit{Ecology}, 99, 1547-1551.
  
\bibitem[MAR11]{Martin2011a}
  Martin, J.; Royle, J. A.; Mackenzie, D. I.; Edwards, H. H.; Kery,
  M. \& Gardner, B. 2011. Accounting for non-independent detection
  when estimating abundance of organisms with a Bayesian
  approach. \textit{Methods in Ecology and Evolution}, 2, 595-601 

\bibitem[MER19]{Merkle2019} 
Merkle, E. C.; Furr, D. \& Rabe-Hesketh, S. 2019. Bayesian Comparison
of Latent Variable Models: Conditional Versus Marginal
Likelihoods. \textit{Psychometrika}, 84, 802-829. 

\bibitem[ROB10]{Robert2010a}
  Robert, C. P. \& Casella, G. 2010. \textit{Introducing
    Monte Carlo methods with R}, Springer.
  
\bibitem[VEH17]{Vehtari2017} 
Vehtari, A.; Gelman, A. \& Gabry, J. 2017. Practical Bayesian model
evaluation using leave-one-out cross-validation and
WAIC. \textit{Statistics and Computing}, 27, 1413-1432. 
\end{thebibliography}




\end{document}
